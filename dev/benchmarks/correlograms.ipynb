{
 "metadata": {
  "name": "correlograms"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Correlograms\n",
      "\n",
      "Testing different algorithms of correlograms computations, as well as Cython versions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import product\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext line_profiler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Function definitions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### First version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_spike_delays(spiketimes, clusters, clusters_to_update=None,\n",
      "    halfwidth=None):\n",
      "    # size of the histograms\n",
      "    nspikes = len(spiketimes)\n",
      "    \n",
      "    # delays will contain all delays for each pair of clusters\n",
      "    delays = {}\n",
      "\n",
      "    # unique clusters\n",
      "    # counter = Counter(clusters)\n",
      "    clusters_unique = np.unique(clusters)\n",
      "    nclusters = len(clusters_unique)\n",
      "    cluster_max = clusters_unique[-1]\n",
      "    \n",
      "    # clusters to update\n",
      "    if clusters_to_update is None:\n",
      "        clusters_to_update = clusters_unique\n",
      "    clusters_mask = np.zeros(cluster_max + 1, dtype=np.bool)\n",
      "    clusters_mask[clusters_to_update] = True\n",
      "    \n",
      "    # initialize the correlograms\n",
      "    for cl in clusters_to_update:\n",
      "        for i in clusters_unique:\n",
      "            delays[(cl, i)] = []\n",
      "            # delays[(i, cl)] = []\n",
      "\n",
      "    # loop through all spikes, across all neurons, all sorted\n",
      "    for i in range(nspikes):\n",
      "        t0, cl0 = spiketimes[i], clusters[i]\n",
      "        # pass clusters that do not need to be processed\n",
      "        if clusters_mask[cl0]:\n",
      "            # i, t0, c0: current spike index, spike time, and cluster\n",
      "            # boundaries of the second loop\n",
      "            t0min, t0max = t0 - halfwidth, t0 + halfwidth\n",
      "            j = i + 1\n",
      "            # go forward in time up to the correlogram half-width\n",
      "            # for j in range(i + 1, nspikes):\n",
      "            while j < nspikes:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # if clusters_mask[cl1]:\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                # if t0min <= t1 <= t0max:\n",
      "                if t1 <= t0max:\n",
      "                    d = t1 - t0\n",
      "                    delays[(cl0, cl1)].append(d)\n",
      "                    # delays[(cl1, cl0)].append(-d)\n",
      "                else:\n",
      "                    break\n",
      "                j += 1\n",
      "            j = i - 1\n",
      "            # go backward in time up to the correlogram half-width\n",
      "            while j >= 0:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # if clusters_mask[cl1]:\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                if t0min <= t1:# <= t0max:\n",
      "                    d = t1 - t0\n",
      "                    delays[(cl0, cl1)].append(d)\n",
      "                    # delays[(cl1, cl0)].append(-d)\n",
      "                else:\n",
      "                    break\n",
      "                j -= 1\n",
      "    return delays"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_correlograms(spiketimes, clusters, clusters_to_update=None,\n",
      "    ncorrbins=100, corrbin=.001):\n",
      "    # Ensure ncorrbins is an even number.\n",
      "    assert ncorrbins % 2 == 0\n",
      "    \n",
      "    # Compute the histogram corrbins.\n",
      "    # n = int(np.ceil(halfwidth / corrbin))\n",
      "    n = ncorrbins // 2\n",
      "    bins = np.arange(ncorrbins + 1) * corrbin - n * corrbin\n",
      "    halfwidth = corrbin * n\n",
      "    \n",
      "    # Compute all delays between any two close spikes.\n",
      "    delays_pairs = compute_spike_delays(spiketimes, clusters,\n",
      "                                  clusters_to_update=clusters_to_update,\n",
      "                                  halfwidth=halfwidth)\n",
      "        \n",
      "    \n",
      "    # Compute the histograms of the delays.\n",
      "    correlograms = {}\n",
      "    for (cl0, cl1), delays in delays_pairs.iteritems():\n",
      "        h, _ = np.histogram(delays, bins=bins)\n",
      "        h[(len(h) + 1) / 2] = 0\n",
      "        correlograms[(cl0, cl1)] = h\n",
      "        \n",
      "    return correlograms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Second version"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_correlograms2(spiketimes, clusters, clusters_to_update=None,\n",
      "    ncorrbins=100, corrbin=.001):\n",
      "    # Ensure ncorrbins is an even number.\n",
      "    assert ncorrbins % 2 == 0\n",
      "    \n",
      "    # Compute the histogram corrbins.\n",
      "    # n = int(np.ceil(halfwidth / corrbin))\n",
      "    n = ncorrbins // 2\n",
      "    halfwidth = corrbin * n\n",
      "    \n",
      "    # size of the histograms\n",
      "    nspikes = len(spiketimes)\n",
      "\n",
      "    # delays will contain all delays for each pair of clusters\n",
      "    delays = {}\n",
      "\n",
      "    # unique clusters\n",
      "    # counter = Counter(clusters)\n",
      "    clusters_unique = np.unique(clusters)\n",
      "    nclusters = len(clusters_unique)\n",
      "    cluster_max = clusters_unique[-1]\n",
      "    \n",
      "    # clusters to update\n",
      "    if clusters_to_update is None:\n",
      "        clusters_to_update = clusters_unique\n",
      "    clusters_mask = np.zeros(cluster_max + 1, dtype=np.bool)\n",
      "    clusters_mask[clusters_to_update] = True\n",
      "    \n",
      "    # initialize the correlograms\n",
      "    correlograms = np.zeros(\n",
      "        ((cluster_max + 1) ** 2, ncorrbins), dtype=np.int32)\n",
      "\n",
      "    # loop through all spikes, across all neurons, all sorted\n",
      "    for i in range(nspikes):\n",
      "        t0, cl0 = spiketimes[i], clusters[i]\n",
      "        # pass clusters that do not need to be processed\n",
      "        if clusters_mask[cl0]:\n",
      "            # i, t0, c0: current spike index, spike time, and cluster\n",
      "            # boundaries of the second loop\n",
      "            t0min, t0max = t0 - halfwidth, t0 + halfwidth\n",
      "            j = i + 1\n",
      "            # go forward in time up to the correlogram half-width\n",
      "            while j < nspikes:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # if clusters_mask[cl1]:\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                if t1 <= t0max:\n",
      "                    d = t1 - t0\n",
      "                    k = int(d / corrbin) + n\n",
      "                    #ind = pairs[(cl0, cl1)]\n",
      "                    ind = (cluster_max + 1) * cl0 + cl1\n",
      "                    correlograms[ind, k] += 1\n",
      "                else:\n",
      "                    break\n",
      "                j += 1\n",
      "            j = i - 1\n",
      "            # go backward in time up to the correlogram half-width\n",
      "            while j >= 0:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                if t0min <= t1:\n",
      "                    d = t1 - t0\n",
      "                    k = int(d / corrbin) + n - 1\n",
      "                    #ind = pairs[(cl0, cl1)]\n",
      "                    ind = (cluster_max + 1) * cl0 + cl1\n",
      "                    correlograms[ind, k] += 1\n",
      "                else:\n",
      "                    break\n",
      "                j -= 1\n",
      "    return {(cl0, cl1): correlograms[(cluster_max + 1) * cl0 + cl1,:] for cl0 in clusters_to_update for cl1 in clusters_unique}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "DTYPE = np.double\n",
      "ctypedef np.double_t DTYPE_t\n",
      "DTYPEI = np.int\n",
      "ctypedef np.int_t DTYPEI_t\n",
      "\n",
      "def compute_correlograms2cython(\n",
      "     np.ndarray[DTYPE_t, ndim=1] spiketimes,\n",
      "     np.ndarray[DTYPEI_t, ndim=1] clusters,\n",
      "     np.ndarray[DTYPEI_t, ndim=1] clusters_to_update=None,\n",
      "     int ncorrbins=100,\n",
      "     double corrbin=.001):\n",
      "    \n",
      "    # Ensure ncorrbins is an even number.\n",
      "    assert ncorrbins % 2 == 0\n",
      "    \n",
      "    # Compute the histogram corrbins.\n",
      "    # n = int(np.ceil(halfwidth / corrbin))\n",
      "    cdef int n = ncorrbins // 2\n",
      "    cdef double halfwidth = corrbin * n\n",
      "    \n",
      "    # size of the histograms\n",
      "    cdef int nspikes = len(spiketimes)\n",
      "    \n",
      "    cdef int i, j, cl0, cl1, k, ind\n",
      "    cdef float t0, t1, t0min, t0max, d\n",
      "\n",
      "    # unique clusters\n",
      "    # counter = Counter(clusters)\n",
      "    cdef np.ndarray[DTYPEI_t, ndim=1] clusters_unique = np.unique(clusters)\n",
      "    cdef int nclusters = len(clusters_unique)\n",
      "    cdef int cluster_max = clusters_unique[-1]\n",
      "    \n",
      "    # clusters to update\n",
      "    if clusters_to_update is None:\n",
      "        clusters_to_update = clusters_unique\n",
      "    cdef np.ndarray[DTYPEI_t, ndim=1] clusters_mask = np.zeros(cluster_max + 1, dtype=DTYPEI)\n",
      "    clusters_mask[clusters_to_update] = 1\n",
      "    \n",
      "    # initialize the correlograms\n",
      "    cdef np.ndarray[DTYPEI_t, ndim=2] correlograms = np.zeros(\n",
      "        ((cluster_max + 1) ** 2, ncorrbins), dtype=DTYPEI)\n",
      "\n",
      "    # loop through all spikes, across all neurons, all sorted\n",
      "    for i in xrange(nspikes):\n",
      "        t0, cl0 = spiketimes[i], clusters[i]\n",
      "        # pass clusters that do not need to be processed\n",
      "        if clusters_mask[cl0]:\n",
      "            # i, t0, c0: current spike index, spike time, and cluster\n",
      "            # boundaries of the second loop\n",
      "            t0min, t0max = t0 - halfwidth, t0 + halfwidth\n",
      "            j = i + 1\n",
      "            # go forward in time up to the correlogram half-width\n",
      "            while j < nspikes:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # if clusters_mask[cl1]:\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                if t1 < t0max:\n",
      "                    d = t1 - t0\n",
      "                    k = int(d / corrbin) + n\n",
      "                    #ind = pairs[(cl0, cl1)]\n",
      "                    ind = (cluster_max + 1) * cl0 + cl1\n",
      "                    correlograms[ind, k] += 1\n",
      "                else:\n",
      "                    break\n",
      "                j += 1\n",
      "            j = i - 1\n",
      "            # go backward in time up to the correlogram half-width\n",
      "            while j >= 0:\n",
      "                t1, cl1 = spiketimes[j], clusters[j]\n",
      "                # pass clusters that do not need to be processed\n",
      "                # compute only correlograms if necessary\n",
      "                # and avoid computing symmetric pairs twice\n",
      "                if t0min < t1:\n",
      "                    d = t1 - t0\n",
      "                    k = int(d / corrbin) + n - 1\n",
      "                    #ind = pairs[(cl0, cl1)]\n",
      "                    ind = (cluster_max + 1) * cl0 + cl1\n",
      "                    correlograms[ind, k] += 1\n",
      "                else:\n",
      "                    break\n",
      "                j -= 1\n",
      "    return {(cl0, cl1): correlograms[(cluster_max + 1) * cl0 + cl1,:] for cl0 in clusters_to_update for cl1 in clusters_unique}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nspikes = 100000\n",
      "nclusters = 200\n",
      "ncorrbins = 100\n",
      "corrbin = .001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spiketimes = np.cumsum(np.random.exponential(scale=.01, size=nspikes))\n",
      "clusters = np.random.randint(low=0, high=nclusters - 1, size=nspikes)\n",
      "indices_sorting = np.argsort(spiketimes)\n",
      "spiketimes = spiketimes[indices_sorting]\n",
      "clusters = clusters[indices_sorting]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correlograms1 = compute_correlograms(spiketimes, clusters,\n",
      "                                    ncorrbins=ncorrbins, corrbin=corrbin)\n",
      "correlograms2 = compute_correlograms2(spiketimes, clusters,\n",
      "                                    ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Benchmarks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### First version\n",
      "\n",
      "Original version, with delays stored, then np.histogram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit -n 2 -r 2\n",
      "correlograms = compute_correlograms(spiketimes, clusters,\n",
      "                                    ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 loops, best of 2: 1.01 s per loop\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Second version\n",
      "\n",
      "Improved version, with histograms computed online, no delays stored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit -n 2 -r 2\n",
      "correlograms = compute_correlograms2(spiketimes, clusters,\n",
      "                                     ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 loops, best of 2: 5.33 s per loop\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit -n 2 -r 2\n",
      "correlograms = compute_correlograms2cython(spiketimes, clusters,\n",
      "                                    ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 loops, best of 2: 114 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correlograms = compute_correlograms2(spiketimes, clusters,\n",
      "                                     ncorrbins=ncorrbins, corrbin=corrbin)\n",
      "correlograms_cython = compute_correlograms2cython(spiketimes, clusters,\n",
      "                                    ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print correlograms[2,2]-correlograms_cython[2,2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
        "  0  0  0  0  0  0  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0  0  0  1 -1\n",
        " -1  1  0  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
        "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print set(correlograms.keys()) == set(correlograms_cython.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Line-by-line profiling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f compute_correlograms2 compute_correlograms2(spiketimes, clusters, ncorrbins=ncorrbins, corrbin=corrbin)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    }
   ],
   "metadata": {}
  }
 ]
}